* [Efficiency of Nature](https://www.linkedin.com/posts/sai-kumar-mishra-6811221a4_a-delhi-metro-trip-will-always-hold-a-special-activity-7174372044292202496-d1-x?utm_source=share&utm_medium=member_desktop)
    > The genius of simplicity lies in an intelligence that makes complex information so simple that it can be repeated; the intelligence shines in two aspects &mdash; the ease of replicability and the complexity that can be reconstructed from it.

* [Order of Complexity](https://www.linkedin.com/feed/update/urn:li:activity:7166503556903026689?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7166503556903026689%2C7166710751779340289%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287166710751779340289%2Curn%3Ali%3Aactivity%3A7166503556903026689%29)
    > <p>If anyone has ever taken a class in computational complexity, they know there's a very simple way of thinking about these problems (solving it is another story though). We measure algorithms based on their space-time-accuracy-confidence complexity, and every algorithm (including the RL/linear transformer algorithms) is subsumed under this evaluation. And research is directed at minimising in prioritised order these characteristics. In fact, if you build a meta-algorithm for searching for the most optimal algorithm, that algorithm itself would be subject to this multi-way seesaw of complexity. And this is akin to the conservation of energy - you cannot create/destroy energy, only convert. Which brings us to this reality - the complexity is not bound to the algorithms, but to the nature of the problem itself, which we did not create - it's absolute in it's complexity. </p>The innovation required, therefore, can either try to jump across the environment state-space and try to adapt the algo to different prioritised optimalities (which will again require a meta-algo), or for the same problem that nature created, try to mine a solver that is also nature provided - which is what quantum compute, organoid intel, etc, are trying to achieve.